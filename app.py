# app.py  â€” Week 9: Dashboard with Database Query (SQLite + Streamlit)
# ---------------------------------------------------------------
# åŠŸèƒ½ï¼š
# 1) ç¢ºä¿ log.db ä»¥åŠ logs è¡¨å­˜åœ¨ï¼›è‹¥æ²’æœ‰è€ŒåŒè³‡æ–™å¤¾æœ‰ log.csvï¼Œæœƒè‡ªå‹•åŒ¯å…¥å»ºç«‹
# 2) å¾ SQLite è®€å–è³‡æ–™ï¼Œæä¾› Ping ç‹€æ…‹ç¯©é¸
# 3) é¡¯ç¤ºæœ€è¿‘ 5 ç­†ç´€éŒ„ã€ä¸‰å¼µæŠ˜ç·šåœ–ï¼ˆCPU / Memory / Diskï¼‰ï¼Œèˆ‡ç°¡å–®çµ±è¨ˆ
# ---------------------------------------------------------------

import os
import sqlite3
import pandas as pd
import streamlit as st

DB_PATH = "log.db"
CSV_PATH = "log.csv"
TABLE = "logs"

# ---- å…±åŒå°å·¥å…· -------------------------------------------------

def _open_conn():
    # ç”¨ check_same_thread=False è®“ Streamlit å¤šåŸ·è¡Œç·’æ™‚ä¹Ÿèƒ½è®€
    return sqlite3.connect(DB_PATH, check_same_thread=False)

def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """æŠŠæ¬„ä½åçµ±ä¸€æˆä½œæ¥­è¦æ ¼ï¼šTimestamp, CPU, Memory, Disk, Ping_Status, Ping_ms"""
    wanted = ["Timestamp", "CPU", "Memory", "Disk", "Ping_Status", "Ping_ms"]
    # å…ˆåšå€‹ä¸å€åˆ†å¤§å°å¯«çš„å°ç…§
    lower_map = {c.lower(): c for c in df.columns}
    out = {}
    for w in wanted:
        key = w.lower()
        if key in lower_map:
            out[w] = df[lower_map[key]]
        elif w in df.columns:
            out[w] = df[w]
        else:
            # è‹¥ç¼ºæ¬„ä½ï¼Œè£œç©ºå€¼
            out[w] = pd.Series([None] * len(df))
    df2 = pd.DataFrame(out)
    # è½‰æ™‚é–“
    if "Timestamp" in df2.columns:
        df2["Timestamp"] = pd.to_datetime(df2["Timestamp"], errors="coerce")
    # æ•¸å€¼æ¬„ä½è½‰ float
    for col in ["CPU", "Memory", "Disk", "Ping_ms"]:
        if col in df2.columns:
            df2[col] = pd.to_numeric(df2[col], errors="coerce")
    # Ping_Status è½‰å­—ä¸²
    if "Ping_Status" in df2.columns:
        df2["Ping_Status"] = df2["Ping_Status"].astype(str)
    return df2

# ---- DB æº–å‚™ ----------------------------------------------------

def ensure_db_and_table():
    """ç¢ºä¿ DB èˆ‡è¡¨å­˜åœ¨ï¼›è‹¥æœ‰ log.csv å‰‡åŒ¯å…¥æˆ logs è¡¨ï¼Œå¦å‰‡å»ºç©ºè¡¨ã€‚"""
    conn = _open_conn()
    cur = conn.cursor()
    cur.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?;", (TABLE,))
    exists = cur.fetchone() is not None

    if not exists:
        if os.path.exists(CSV_PATH):
            csv_df = pd.read_csv(CSV_PATH)
            csv_df = _normalize_columns(csv_df)
            # å¯«å…¥ SQLite å‰æŠŠæ™‚é–“è½‰æˆ ISO å­—ä¸²ï¼Œé¿å…å‹åˆ¥æ··äº‚
            if "Timestamp" in csv_df.columns:
                csv_df["Timestamp"] = csv_df["Timestamp"].dt.strftime("%Y-%m-%d %H:%M:%S")
            csv_df.to_sql(TABLE, conn, index=False, if_exists="replace")
            st.info("å·²å¾ log.csv å»ºç«‹ log.db çš„ logs è¡¨ã€‚")
        else:
            cur.execute(
                f"""
                CREATE TABLE IF NOT EXISTS {TABLE} (
                    Timestamp   TEXT,
                    CPU         REAL,
                    Memory      REAL,
                    Disk        REAL,
                    Ping_Status TEXT,
                    Ping_ms     REAL
                );
                """
            )
            conn.commit()
            st.warning("æ‰¾ä¸åˆ° log.csvï¼Œå·²å…ˆå»ºç«‹ç©ºçš„ logs è¡¨ã€‚è«‹ä¸Šå‚³/ç”¢ç”Ÿæ—¥èªŒå¾Œå†é‡æ•´ã€‚")
    conn.close()

def load_all() -> pd.DataFrame:
    """è®€å‡ºå…¨éƒ¨è³‡æ–™ï¼ˆä¾æ™‚é–“æ’åºï¼‰ï¼Œä¸¦è½‰å›åˆé©å‹åˆ¥ã€‚"""
    conn = _open_conn()
    try:
        df = pd.read_sql_query(f"SELECT * FROM {TABLE}", conn)
    finally:
        conn.close()

    if df.empty:
        return df

    df = _normalize_columns(df)
    return df.sort_values("Timestamp")

# ---- Streamlit UI ----------------------------------------------

st.set_page_config(page_title="è³‡æ–™ä¸­å¿ƒç›£æ§å„€è¡¨æ¿", layout="wide")
st.title("ğŸ“Š è³‡æ–™ä¸­å¿ƒç›£æ§å„€è¡¨æ¿")

# æº–å‚™è³‡æ–™è¡¨
ensure_db_and_table()
df_all = load_all()

if df_all.empty:
    st.info("è³‡æ–™åº«ç›®å‰æ²’æœ‰è³‡æ–™ï¼ˆæˆ–å‰›å»ºç«‹ï¼‰ã€‚è«‹å…ˆåœ¨ Week 7 çš„ logger ç”¢ç”Ÿè³‡æ–™ï¼Œå†å›åˆ°é€™è£¡é‡æ•´é é¢ã€‚")
    st.stop()

# å´é‚Šæ¬„ï¼šPing ç‹€æ…‹ç¯©é¸
with st.sidebar:
    st.header("ç¯©é¸")
    selected = st.selectbox("æŒ‰ Ping ç‹€æ…‹ç¯©é¸", ["å…¨éƒ¨", "UP", "DOWN"], index=0)

df = df_all.copy()
if selected != "å…¨éƒ¨":
    df = df[df["Ping_Status"] == selected]

st.caption(f"é¡¯ç¤ºç­†æ•¸ï¼š{len(df)}ã€€ï¼ˆç¸½ç­†æ•¸ï¼š{len(df_all)}ï¼‰")
if "Timestamp" in df.columns and not df.empty:
    earliest = df["Timestamp"].min()
    latest = df["Timestamp"].max()
    st.caption(f"æ™‚é–“ç¯„åœï¼š{earliest} ã€œ {latest}")

# æœ€è¿‘ 5 ç­†ç´€éŒ„
st.subheader("æœ€å¾Œ 5 ç­†ç´€éŒ„")
st.dataframe(df.tail(5), use_container_width=True)

# KPIï¼ˆé¡¯ç¤ºæœ€æ–°ä¸€ç­†ï¼‰
if not df.empty:
    latest_row = df.iloc[-1]
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("CPUï¼ˆ%ï¼‰", f"{latest_row.get('CPU', float('nan')):.1f}")
    c2.metric("Memoryï¼ˆ%ï¼‰", f"{latest_row.get('Memory', float('nan')):.1f}")
    c3.metric("Diskï¼ˆ%ï¼‰", f"{latest_row.get('Disk', float('nan')):.1f}")
    c4.metric("Ping (ms)", f"{latest_row.get('Ping_ms', float('nan')):.1f}")

# ä¸‰å¼µæŠ˜ç·šåœ–
st.subheader("è¶¨å‹¢")
chart_base = df.dropna(subset=["Timestamp"]).set_index("Timestamp")
col1, col2, col3 = st.columns(3)

with col1:
    if "CPU" in chart_base.columns:
        st.caption("CPU ä½¿ç”¨ç‡")
        st.line_chart(chart_base["CPU"])
with col2:
    if "Memory" in chart_base.columns:
        st.caption("è¨˜æ†¶é«”ä½¿ç”¨ç‡")
        st.line_chart(chart_base["Memory"])
with col3:
    if "Disk" in chart_base.columns:
        st.caption("ç£ç¢Ÿä½¿ç”¨ç‡")
        st.line_chart(chart_base["Disk"])

st.success("å„€è¡¨æ¿å·²è¼‰å…¥ âœ…")
